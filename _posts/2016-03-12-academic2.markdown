---
layout: post
title:  "闲话|从AlphaGo战胜李世石说起（2）"
date:   2016-03-12 20:19:26 +0800
categories: Academic
abstract: 第三局李世石和阿法狗的人机大战已经结束，阿法狗连下三城3:0领先，提前获得了这次比赛的胜利。到现在这个阶段，我想阿法狗的实力在人类最顶尖棋手之上应该已经争议不大了。围棋，这一个“人类智慧最后的堡垒”终于被人工智能击溃，那么还有什么是机器做不到的呢？我们接着上次的话题，讨论一下机器还不能做什么。
---

<p style="text-align:left">
第三局李世石和阿法狗的人机大战已经结束，阿法狗连下三城3:0领先，提前获得了这次比赛的胜利。到现在这个阶段，我想阿法狗的实力在人类最顶尖棋手之上应该已经争议不大了。围棋，这一个“人类智慧最后的堡垒”终于被人工智能击溃，那么还有什么是机器做不到的呢？我们接着上次的话题，讨论一下机器还不能做什么。
</p>

<ul style="text-align:left;list-style:circle;list-style-position:inside">
	<li><a href="http://daib13.github.io/academic/2016/03/09/academic1.html">机器能否战胜人类</a></li>
	<li style="color:red">机器还不能做什么</li>
	<li>当我谈人工智能时我在说什么</li>
	<li>漫话形上学、科学、技术与数学</li>
</ul>


<p style="text-align:left">
机器还不能做什么，在不同的时代会有不同的回答。在半年前，机器还不能在围棋上战胜哪怕是最差劲的职业棋手。而现在，机器显然已经远远突破了我们之前认为的上限。所以哪怕我现在举出一百个例子告诉你，机器还不能干啥干啥，你都可以说：“说不定以后机器可以做到呢？”所以我行文之时必须格外小心，并需要阐明机器是否有机会去做成这件事情。
</p>

<p style="text-align:left">
有人说，阿法狗无非是通过大量数据记住了高手们的招式，然后通过搜索得出最有利的下法罢了，它不会自己进行创新。那么阿法狗事实上能创新吗？回答应该是可以的。事实上，就在阿法狗的实现中，就有常见的“创新”方式。我所理解的创新，是在一定的框架下面，突破陈旧的套路，寻求新的可行的方式。而在阿法狗的实现里面，创新，就是鼓励机器去探索那些不太被看好的下子方案。我们看到谷歌那篇论文的第三页，在搜索的时候，每一步的落子方案a是取Q+u最大的那种，其中Q可以认为是在墨守成规的情况下的评价函数，而u文中称为bonus，也就是鼓励“创新”的那一项。这一项是如何来鼓励创新的呢？我们看到u的表达式，它与N(s,a)负相关，也就是说，当面对这样的局面s时，如果你经常采取a方案，则会产生“厌倦”，从而降低bonus项，也就让那些本来没有机会的被采取的方案获得了机会，这是某种意义上的创新。
</p>

<img src="/images/posts/innovation.jpg"/>

<p style="text-align:left">
你可能会说这样的“创新”真是一点都不创新。我同意，在“创新”这一点上，机器还处于很低级的阶段，而且这一项创新到底有多大的作用还说不清，仍然需要人类更多智慧的注入，但是毫无疑问，在现阶段，机器已经会初等的“创新”了。这有可能也是阿法狗会走出一些让人不明所以而实际证明是很高明的招数的原因吧。
</p>

<p style="text-align:left">
我们再次回到阿法狗，这两天我们老是可以看到这样的评论“我就想问阿法狗在走这步棋时有没有犹豫”、“阿法狗现在下得很轻松了”…但其实我们知道，阿法狗在下棋的时候是没有“犹豫”、“轻松”这样的概念的，也就是说，它没有情绪。那么机器能拥有情绪吗？我说，在目前这个阶段，机器没有情绪，但是在以后，机器可能会有情绪。举个例子，如果我想让阿法狗获得“乐观”和“悲观”这两种情绪，这其实是很直接的，让阿法狗对当前的局势进行判断，如果判断出来胜率比较低，就比较“悲观”，从而设置一些“悲观”相关的表现，比如在落子的时候倾向于对战斗激烈的局部舍弃。当判断出来胜率逐渐走高，就产生一些“乐观”的表现，比如说主动寻求战斗。进一步地，可以有“犹豫”，比如对于高风险高回报的步骤表现出“犹豫”，也就是增大搜索深度，相当于人的延长思考时间。也可以有“轻松”“得意忘形”，在局势较有利时减小搜索深度，缩短了落子时间的同时也增大了判断失误的可能性。
</p>

<p style="text-align:left">
你当然可以反驳说这算哪门子情绪，这都太教条化了。我必须说，当这些教条足够细致地时候，你感觉到的计算机就是拥有情绪的。至于“计算机拥有情绪”能产生多大的价值，我不敢妄下定论，至少，目前来说，是没有什么价值的，也就很少有人（如果有的话）去研究这方面的东西。
</p>

<p style="text-align:left">
暂且假设你已经被我说服计算机是可以拥有情绪的，那么讲了半天，到底什么是计算机不能做的呢？我指的是，那种以后也不能做的事情。我想对于这个问题的答案，前文已经给出了我的观点——没有被定义的东西。我在说“创新”的时候，我事先给出了“创新”的定义，或许和你给出的定义不同，但至少我给了并用数学的形式表达了出来。我在说情绪的时候，我也分门别类的给出了各种“情绪”的激发方式和拥有这种“情绪”时的表现方式，虽然这些“情绪”都相当粗糙。这些描述最终都会被定义成数学的表达式，然后扔进整个系统里面去默默地发挥作用。
</p>

<p style="text-align:left">
计算机的本质是计算，所以必须有可以被计算的东西。刚才所提到的情绪，进一步地，嗅觉味觉触觉等等，都暂时还没有人去把它们定义成数学，所以计算机暂时是没有这部分的能力的。你可以参考我上面的方式，开始定义一些事情，然后在实践中逐步修正改进，从而让计算机（或者机器人？）拥有这些能力并逐渐细化。现在你可以说，问题实在是太简单了，我把我想要让计算机拥有的能力都定义出来，做出数学的表达式，那不就可以让计算机无所不能了么？比如我想让计算机拥有人类的思考方式。
</p>

<p style="text-align:left">
现在问题开始变得危险并走向很多务实的计算机科学家们不喜欢的方向了。有些科幻小说家则津津乐道于此类问题。不过，以我的哲学，是不允许这样的事情发生的。我必须明确地阐明我的观点：有些事情是不能被定义的。或者说，有些事情，一旦被定义出来，那就不是它实际上的样子了。比如说：智能。我断定，你无法说清楚人的智能是怎么一回事。你当然可以给出一些对智能的合理的描述（比如围棋下得好），然后按照这套描述去实现（比如养条阿法狗），但那是智能的一部分能力，不是全部。
</p>

<p style="text-align:left">
你无法完整地定义智能，计算机不可能成为像人一样的智慧生物（或者智慧机器），这是我的观点。既然如此，当我在说“人工智能”这四个字的时候，又意味着什么呢？我将在下一篇文章中说明“当我谈人工智能时我在说什么”。
</p>
